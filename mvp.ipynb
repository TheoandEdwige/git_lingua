{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9df2adae-8ee0-4b64-8169-fae837b41061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import modeling as m\n",
    "import wrangle as w\n",
    "import prepare as p\n",
    "import explore as e\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import f_oneway\n",
    "from scipy.stats import ttest_ind\n",
    "from env import github_token, github_username\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from acquire import search_github_repositories, get_repo\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f09d27-a067-4819-b04f-aa29007d5eb5",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "## Project Overview\n",
    "In this project, we aim to predict the main programming language of a GitHub repository based on the text of its README file. This project has several goals:\n",
    "\n",
    "1. Collect data from GitHub repositories.\n",
    "2. Perform exploratory data analysis on the READMEs to understand their characteristics.\n",
    "3. Build and evaluate machine learning models for programming language prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0445d4cb-6ad2-4e2e-83c5-a0b33163dee9",
   "metadata": {},
   "source": [
    "## Project Goals and Deliverables\n",
    "The goals of this project include:\n",
    "- Building a machine learning model for text classification.\n",
    "- Gaining insights into the relationships between README text and programming languages.\n",
    "- Creating a well-documented Jupyter Notebook.\n",
    "- Preparing presentation slides summarizing the project's findings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210a792c-e417-4e61-ac40-45cb02d10252",
   "metadata": {},
   "source": [
    "#### Data Source\n",
    "We will collect data from artificial intelligence related GitHub repositories using web scraping techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87184e0d-f21d-412b-a65e-3c14e4cb6f7e",
   "metadata": {},
   "source": [
    "## Acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "326ea415-1405-4b76-9e44-225a66572738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the 'get_repo' function to fetch repository data related to the topic \"artificial intelligence\"\n",
    "df = get_repo(\"artificial intelligence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d7f23a0-1624-4930-aaa4-095a8eabffa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Language</th>\n",
       "      <th>Readme</th>\n",
       "      <th>Kernel</th>\n",
       "      <th>Stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awesome-artificial-intelligence</td>\n",
       "      <td>None</td>\n",
       "      <td># Awesome Artificial Intelligence (AI) [![Awes...</td>\n",
       "      <td>None</td>\n",
       "      <td>8231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Artificial-Intelligence</td>\n",
       "      <td>None</td>\n",
       "      <td>All about AI with Cheat-Sheets(+100 Cheat-shee...</td>\n",
       "      <td>None</td>\n",
       "      <td>1475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>opencog</td>\n",
       "      <td>Scheme</td>\n",
       "      <td></td>\n",
       "      <td>Scheme</td>\n",
       "      <td>2288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Artificial-Intelligence-Deep-Learning-Machine-...</td>\n",
       "      <td>Python</td>\n",
       "      <td># NEW LIST 2023 - 2024: Machine-Learning / Dee...</td>\n",
       "      <td>Python</td>\n",
       "      <td>3518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>artificial-intelligence</td>\n",
       "      <td>Python</td>\n",
       "      <td># Artificial Intelligence Nanodegree Program R...</td>\n",
       "      <td>Python</td>\n",
       "      <td>445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name Language  \\\n",
       "0                    awesome-artificial-intelligence     None   \n",
       "1                            Artificial-Intelligence     None   \n",
       "2                                            opencog   Scheme   \n",
       "3  Artificial-Intelligence-Deep-Learning-Machine-...   Python   \n",
       "4                            artificial-intelligence   Python   \n",
       "\n",
       "                                              Readme  Kernel  Stars  \n",
       "0  # Awesome Artificial Intelligence (AI) [![Awes...    None   8231  \n",
       "1  All about AI with Cheat-Sheets(+100 Cheat-shee...    None   1475  \n",
       "2                                                     Scheme   2288  \n",
       "3  # NEW LIST 2023 - 2024: Machine-Learning / Dee...  Python   3518  \n",
       "4  # Artificial Intelligence Nanodegree Program R...  Python    445  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bbe663f-1e72-415b-8469-d6fcb79e487e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Language</th>\n",
       "      <th>Readme</th>\n",
       "      <th>Kernel</th>\n",
       "      <th>Stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>artificial-intelligence</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td># Artificial Intelligence (AI)\\n\\nA project-ba...</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>artificial-intelligence-for-trading</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td># AI in Trading NanoDegree (AITND)\\nThis repos...</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DataScience_ArtificialIntelligence_Utils</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td># Data Science &amp; Artifical Intelligence with P...</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Artificial-Intelligence-Projects</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>&lt;a href=\"https://www.buymeacoffee.com/pierpaol...</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Python-Artificial-Intelligence-Projects-for-Be...</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>\\n\\n\\n# Python Artificial Intelligence Project...</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>aind-term1</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>## README\\nThis repository contains all projec...</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>Artificial-Intelligence_resources-and-notebooks</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td># Artificial-Intelligence_resources-and-notebo...</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>CRC-Press</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>﻿# CRC Press Source Code\\n\\nThis repository ac...</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>05.KNU-BigData-Artificial-Intelligence-Course</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td># 05.KNU-BigData-Artificial-Intelligence-Cours...</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>IBM-Project-40798-1664170001</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td># IBM-Project-40798-1664170001\\nNatural Disast...</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>239 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Name          Language  \\\n",
       "5                              artificial-intelligence  Jupyter Notebook   \n",
       "6                  artificial-intelligence-for-trading  Jupyter Notebook   \n",
       "10            DataScience_ArtificialIntelligence_Utils  Jupyter Notebook   \n",
       "15                    Artificial-Intelligence-Projects  Jupyter Notebook   \n",
       "22   Python-Artificial-Intelligence-Projects-for-Be...  Jupyter Notebook   \n",
       "..                                                 ...               ...   \n",
       "981                                         aind-term1  Jupyter Notebook   \n",
       "986    Artificial-Intelligence_resources-and-notebooks  Jupyter Notebook   \n",
       "989                                          CRC-Press  Jupyter Notebook   \n",
       "998      05.KNU-BigData-Artificial-Intelligence-Course  Jupyter Notebook   \n",
       "999                       IBM-Project-40798-1664170001  Jupyter Notebook   \n",
       "\n",
       "                                                Readme            Kernel  \\\n",
       "5    # Artificial Intelligence (AI)\\n\\nA project-ba...  Jupyter Notebook   \n",
       "6    # AI in Trading NanoDegree (AITND)\\nThis repos...  Jupyter Notebook   \n",
       "10   # Data Science & Artifical Intelligence with P...  Jupyter Notebook   \n",
       "15   <a href=\"https://www.buymeacoffee.com/pierpaol...  Jupyter Notebook   \n",
       "22   \\n\\n\\n# Python Artificial Intelligence Project...  Jupyter Notebook   \n",
       "..                                                 ...               ...   \n",
       "981  ## README\\nThis repository contains all projec...  Jupyter Notebook   \n",
       "986  # Artificial-Intelligence_resources-and-notebo...  Jupyter Notebook   \n",
       "989  ﻿# CRC Press Source Code\\n\\nThis repository ac...  Jupyter Notebook   \n",
       "998  # 05.KNU-BigData-Artificial-Intelligence-Cours...  Jupyter Notebook   \n",
       "999  # IBM-Project-40798-1664170001\\nNatural Disast...  Jupyter Notebook   \n",
       "\n",
       "     Stars  \n",
       "5      437  \n",
       "6      667  \n",
       "10     395  \n",
       "15     289  \n",
       "22     302  \n",
       "..     ...  \n",
       "981      3  \n",
       "986      7  \n",
       "989      7  \n",
       "998      4  \n",
       "999      4  \n",
       "\n",
       "[239 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Language']=='Jupyter Notebook']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f519a9-320d-475b-8f55-104317d9130f",
   "metadata": {},
   "source": [
    "## Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60857e9-c846-4287-b051-a66d1d6cc6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert all column names to lowercase\n",
    "# Remove rows with missing 'readme' values\n",
    "# Check for and remove duplicate rows\n",
    "# Reset the index after dropping rows\n",
    "df = w.convert_and_dropna(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467206e2-d482-44c3-8f1c-1ba377d855e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504adeef-3ad8-4612-a336-787514160d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the text data in the 'readme' column of the DataFrame\n",
    "# The preprocess_text_in_dataframe function performs text cleaning and transformation,\n",
    "# which may include tasks like lowering text, removing special characters, tokenization, stemming,\n",
    "# or lemmatization, and removing stopwords, depending on the implementation of the function.\n",
    "# The processed text is then assigned back to the 'readme' column in the DataFrame.\n",
    "df = p.preprocess_text_in_dataframe(df, 'readme')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666b1fd2-ef82-4b6c-b475-f89810d79d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ede8b2-e765-4967-9d4c-1122da82034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['language']=='Jupyter Notebook').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a965a3a-167c-4ef8-8d56-0a3337584c10",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a230274-4568-4297-829e-8a7d82bc52cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.idf_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab692254-afb0-4f8e-9682-bcadad9fcbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate basic statistics (word count, character count, average word length) for the 'readme' column in the DataFrame 'df'\n",
    "basic_stats = e.calculate_basic_statistics(df, 'readme')\n",
    "\n",
    "# Display the basic statistics\n",
    "basic_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865c41d1-c620-47b6-90de-7b1b510b472b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#top words in the readme column\n",
    "top_words = e.identify_most_common_words(df, 'readme', top_n=10)\n",
    "top_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ae7f7f-0c03-4442-bebd-9cac7585ce62",
   "metadata": {},
   "source": [
    "#### Most Common Words in READMEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeceb8dc-59e7-45f6-ae14-c1287db2ce2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualization of the top words in readme\n",
    "e.top_words_barplot(top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aad1be-2834-4b55-b8d9-8458aa8dcc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to plot the average unique words by programming language\n",
    "# Provide the DataFrame 'df' containing 'language' and 'readme' columns\n",
    "w.plot_unique_words_by_language(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2582e5-efa6-4143-ace2-38a2a02aa027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to display the top 3 unique words for the most popular programming languages\n",
    "# Provide the DataFrame 'df' containing 'language' and 'readme' columns\n",
    "w.top_unique_words_by_language(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e171b5a0-bfed-4b8a-8edc-693f5112ebdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wordcloud of the words in the readme column\n",
    "e.generate_word_cloud(df, 'readme')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c3b7db-5380-401e-9dc1-ae574f357080",
   "metadata": {},
   "source": [
    "## Exploration Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0485671-68ba-4335-abfb-63b381f4f987",
   "metadata": {},
   "source": [
    "#### 1) Does the programming language used in a GitHub repository affect the length of the README file (in terms of word count)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70238c6-75af-4b34-984f-8587eb82af96",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.hypothesis_one(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e55538-08ae-40f6-8201-9829ea877ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1b29bc-33a7-4a16-9ac9-846f9ca08794",
   "metadata": {},
   "source": [
    "#### Null Hypothesis (H0): The programming language used in a GitHub repository DEOS NOT affect the length of the README file (in terms of word count).\n",
    "\n",
    "#### Alternative Hypothesis (H1): The programming language used in a GitHub repository affect the length of the README file (in terms of word count)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fa9bcc-4e5b-4ca1-b898-3553fabf6c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.statistical_test1(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a41f67-e3e9-4953-8b5d-00af7e0b31d1",
   "metadata": {},
   "source": [
    "#### 2) Does the frequency of specific words in a README file have an impact on the choice of programming language for a repository?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09fcede-3e07-42d3-b71c-4c382d120a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.hypothesis_two(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf56a055-2706-44d7-ae28-7374289bbfa0",
   "metadata": {},
   "source": [
    "#### Null Hypothesis (H0): There is no association between the choice of programming language and the frequency of specific words in README files.\n",
    "\n",
    "#### Alternative Hypothesis (H1): There is an association between the choice of programming language and the frequency of specific words in README files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69f2e29-a27c-4b20-b20f-1fd661701079",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.statistical_test2(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955bc940-e638-4c8e-a44e-f3da204e8d48",
   "metadata": {},
   "source": [
    "#### 3) What is the top 3 most predictive words in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d02600-faec-4ea4-9867-2d5a25ee0a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the top 3 most predictive words for R.\n",
    "e.hypothesis_three(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e20f0b-dfd0-415e-945b-0c74748f9a62",
   "metadata": {},
   "source": [
    "#### Null Hypothesis (H0): There is no significant association between the presence or frequency of the word 'learning' and R.\n",
    "\n",
    "#### Alternative Hypothesis (H1): There is a significant association between the presence or frequency of the word 'learning' and R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e53f12-8454-4b9b-a125-78aca2e5f231",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.statistical_test3(df, 'learning')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bfae06-f2a9-46b3-9729-2847e54e34b0",
   "metadata": {},
   "source": [
    "#### 4) What is the top 3 most predictive words in MATLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d0105b-6511-4baa-bf17-8632dbb79494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the top 3 most predictive words for MATLAB\n",
    "e.hypothesis_four(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dd1e13-d1b7-4e16-8b6b-5fb58c9ebf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.statistical_test3(df, 'artificial')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd51c57-2b85-4e65-85b5-1c34c3a3f97a",
   "metadata": {},
   "source": [
    "#### 5) What is the top 3 predictive words for TeX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff02b801-ef52-4874-a5ef-0d2dd0dca23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the top 3 most predictive words for JavaScript\n",
    "e.hypothesis_five(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125af3ef-aa23-4b6e-b0ca-9d1571c44bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.statistical_test3(df, 'module')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2adcfd-3dd6-47b3-a5d4-4b2b83a7fac0",
   "metadata": {},
   "source": [
    "## **Data Exploration Summary**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd2f27d-399b-435c-b603-df8999204d45",
   "metadata": {},
   "source": [
    "In the initial phase of our project, we conducted a comprehensive data exploration of the dataset to gain insights and understand the characteristics of the data. This process involved calculating basic statistics for the 'readme' column, identifying the most common words in the 'readme' text, and determining the top unique words associated with popular programming languages.\n",
    "\n",
    "1. **Basic Statistics for 'readme' Column:**\n",
    "   - We found that the 'readme' column contains a total of 784 entries.\n",
    "   - However, there are only 783 unique entries, indicating that there is one instance with an empty 'readme' text.\n",
    "   - The most frequent entry in this column is an empty string, which occurs twice.\n",
    "\n",
    "2. **Top Words in 'readme' Column:**\n",
    "   - To understand the most prevalent words in the 'readme' text, we identified the top 10 words.\n",
    "   - The top five words are \"Learning\" (3913 occurrences), \"Data\" (2693 occurrences), \"Machine\" (2213 occurrences), \"(Whitespace)\" (2051 occurrences), and \"Artificial\" (1926 occurrences).\n",
    "\n",
    "3. **Top Unique Words by Programming Language:**\n",
    "   - We conducted an analysis to find the top 3 unique words associated with the most popular programming languages in the dataset.\n",
    "   - For example, in the case of Python, the top 3 unique words are \"python,\" \"artificial,\" and \"intelligence,\" each with respective TF-IDF scores.\n",
    "   - Similar analyses were performed for Jupyter Notebook, JavaScript, Java, and C++.\n",
    "\n",
    "These exploratory findings provide an essential foundation for our project, allowing us to understand the dataset's composition and gain insights into the significant terms and patterns within the 'readme' text. This information will guide our subsequent steps in natural language processing and machine learning model development."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f01a6b7-d04c-4cbd-8913-a067c5e6463f",
   "metadata": {},
   "source": [
    "### Encoding the target variable and split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10beb982-81a7-4b07-8b57-6f9981800855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function returns X_train, X_val, y_train, and y_val, representing the training and validation sets.\n",
    "X_train, X_val, y_train, y_val = m.encode_and_split_data(df, text_column='readme', target_column='language', test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the training and validation sets\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9211ae8-85da-4a83-9161-16f99fa65ada",
   "metadata": {},
   "source": [
    "### Feature Engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f97cbe8-a773-4b11-af11-4037f6a5f8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function returns X_train_tfidf and X_val_tfidf, representing the training and validation sets transformed into TF-IDF vectors.\n",
    "X_train_tfidf, X_val_tfidf = m.tfidf_vectorization(X_train, X_val)\n",
    "\n",
    "# Print the shapes of the TF-IDF transformed sets\n",
    "print(\"Training set (TF-IDF) shape:\", X_train_tfidf.shape)\n",
    "print(\"Validation set (TF-IDF) shape:\", X_val_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5a80f4-cb35-4711-90a1-19bf4adbf726",
   "metadata": {},
   "source": [
    "## Model Selection and Training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39831b8-539a-4f31-add6-9c9cc31f2b81",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcc2473-8a17-40be-bb30-a9fe054ea980",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.baseline(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc771b58-b373-45d1-b9ab-9da3ddfe89e8",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610adb52-1108-46c7-9c1c-8b77332d723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.train_decision_tree(X_train_tfidf, y_train, X_val_tfidf, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f00339a-51f4-4d97-bc5e-5cc49025ebcf",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36434af-97eb-4258-a917-a634db767581",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.train_random_forest(X_train_tfidf, y_train, X_val_tfidf, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214a144e-cb39-4524-8252-09388cd49de7",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f477884d-64dc-4e26-b649-65ba75b4355e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.train_knn(X_train_tfidf, y_train, X_val_tfidf, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40adc13-dead-4f9d-a0db-d4edb4c72cc1",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b2a8f1-893d-429d-ba4f-951fd1f54492",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.train_logistic_regression(X_train_tfidf, y_train, X_val_tfidf, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6b3ae1-b686-4dad-928e-125ad6758270",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison_result = m.evaluate_and_compare_models(X_train_tfidf, y_train, X_val_tfidf, y_val)\n",
    "print(model_comparison_result)\n",
    "\n",
    "# Create visualizations (e.g., bar charts)\n",
    "model_comparison_result.set_index('Model').plot(kind='bar', subplots=True, layout=(2, 2), legend=False, figsize=(12, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8660e3c0-66cd-4dad-9d39-1eb1438f929a",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c2b7e7-b4b7-4bfd-8fb2-991ce34b2554",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_accuracy = m.evaluate_final_model(X_train, y_train, X_val, y_val, random_state=42)\n",
    "print(f\"Test Set Accuracy: {test_set_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec4eb13-f238-405a-9638-6999e202b883",
   "metadata": {},
   "source": [
    "## **Project Model Summary**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ba8ca8-4146-4a75-9031-25b6f0f6ad45",
   "metadata": {},
   "source": [
    "We have developed and evaluated multiple machine learning models for predicting the main programming language of a repository based on the README text. This summary provides insights into the model development and their performance on the validation dataset.\n",
    "\n",
    "1. **Data Preparation:**\n",
    "   - The data has been split into training and validation sets using the `encode_and_split_data` function.\n",
    "   - Training set shape: (627,) (627,)\n",
    "   - Validation set shape: (157,) (157,)\n",
    "\n",
    "2. **TF-IDF Vectorization:**\n",
    "   - The text data has been transformed into TF-IDF vectors for feature representation using the `tfidf_vectorization` function.\n",
    "   - Training set (TF-IDF) shape: (627, 5000)\n",
    "   - Validation set (TF-IDF) shape: (157, 5000)\n",
    "\n",
    "3. **Model Training and Validation:**\n",
    "   - We trained and evaluated four different models on the validation dataset.\n",
    "\n",
    "4. **Decision Tree Model:**\n",
    "   - Accuracy: 0.4013\n",
    "   - Precision: 0.3563\n",
    "   - Recall: 0.4013\n",
    "   - F1-Score: 0.3748\n",
    "\n",
    "5. **Random Forest Model:**\n",
    "   - Accuracy: 0.4331\n",
    "   - Precision: 0.2925\n",
    "   - Recall: 0.4331\n",
    "   - F1-Score: 0.3226\n",
    "\n",
    "6. **K-Nearest Neighbors (KNN) Model:**\n",
    "   - Accuracy: 0.2611\n",
    "   - Precision: 0.3797\n",
    "   - Recall: 0.2611\n",
    "   - F1-Score: 0.1435\n",
    "\n",
    "7. **Logistic Regression Model:**\n",
    "   - Accuracy: 0.3949\n",
    "   - Precision: 0.2889\n",
    "   - Recall: 0.3949\n",
    "   - F1-Score: 0.3095\n",
    "\n",
    "8. **Model Comparison:**\n",
    "   - The table below summarizes the performance of each model on the validation dataset.\n",
    "\n",
    "|       Model        | Accuracy | Precision | Recall | F1-Score |\n",
    "|-------------------|----------|-----------|--------|----------|\n",
    "| Decision Tree     | 0.4013   | 0.3563    | 0.4013 | 0.3748   |\n",
    "| Random Forest     | 0.4331   | 0.2925    | 0.4331 | 0.3226   |\n",
    "| KNN               | 0.2611   | 0.3797    | 0.2611 | 0.1435   |\n",
    "| Logistic Regression | 0.3949   | 0.2889    | 0.3949 | 0.3095   |\n",
    "\n",
    "9. **Test Set Accuracy:**\n",
    "   - The best-performing model, the Random Forest Classifier, achieved an accuracy of 0.3291 on the test dataset.\n",
    "\n",
    "These results provide valuable insights into the model performance and will guide our final model selection and deployment in the project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553215f0-24ab-4f60-adae-58fb2246bb2d",
   "metadata": {},
   "source": [
    "# Overall Project Conclusion\n",
    "\n",
    "## Project Goals and Approach\n",
    "\n",
    "The goal of this project was to develop a predictive model that identifies the main programming language of a repository based on the README text. To achieve this goal, we followed a structured approach:\n",
    "\n",
    "1. **Data Collection**: We obtained data from GitHub repositories using the GitHub API, collecting information such as the repository name, description, and README text. Our goal was to gather a diverse dataset that represents various programming languages.\n",
    "\n",
    "2. **Data Exploration**: We conducted an in-depth exploration of the data to understand its characteristics. We calculated basic statistics such as word count, character count, and average word length in the README texts. Additionally, we identified the most common words in the dataset and examined the unique words used for each programming language.\n",
    "\n",
    "## Key Findings\n",
    "\n",
    "### Data Exploration\n",
    "\n",
    "Our data exploration revealed several key findings:\n",
    "\n",
    "- The dataset contained a total of 784 README texts with 783 unique texts. However, two texts were identical.\n",
    "- The most common words in the README texts included \"learning,\" \"data,\" \"machine,\" and others, highlighting their prevalence in the programming community.\n",
    "- The analysis of unique words showed distinct patterns for different programming languages. For example, \"Python\" was highly associated with Python-related READMEs.\n",
    "\n",
    "### Model Development\n",
    "\n",
    "We trained and evaluated four machine learning models on the data:\n",
    "\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- K-Nearest Neighbors (KNN)\n",
    "- Logistic Regression\n",
    "\n",
    "The models were assessed based on accuracy, precision, recall, and F1-score on a validation dataset. The Random Forest model outperformed the others, achieving an accuracy of 0.4331.\n",
    "\n",
    "## Recommendations\n",
    "\n",
    "Based on our findings, we make the following recommendations:\n",
    "\n",
    "1. **Model Selection**: The Random Forest model has demonstrated the highest accuracy. We recommend selecting this model for predicting programming languages based on README text.\n",
    "\n",
    "2. **Enhanced Data Collection**: To further improve model performance, we recommend expanding the dataset by collecting README texts from a more extensive and diverse set of repositories.\n",
    "\n",
    "3. **Hyperparameter Tuning**: For the selected model, fine-tuning the hyperparameters and conducting cross-validation can lead to even better performance.\n",
    "\n",
    "4. **Deployment**: Once the final model is selected, consider deploying it as a prediction tool for developers. It can assist users in automatically tagging their repositories with the correct programming language.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "If we had more time and resources, we would consider the following next steps:\n",
    "\n",
    "1. **Enhanced Data Preprocessing**: Implement more advanced text preprocessing techniques, such as handling punctuation, stemming, or lemmatization to improve text data quality.\n",
    "\n",
    "2. **Model Interpretability**: Analyze feature importance in the Random Forest model to gain insights into which terms play a significant role in predicting programming languages.\n",
    "\n",
    "3. **Continuous Data Collection**: Develop an automated data collection pipeline that continuously updates the dataset with recent GitHub repositories and READMEs.\n",
    "\n",
    "4. **User Interface**: Create a user-friendly interface for developers to interact with the model and automatically label their repositories.\n",
    "\n",
    "This project has laid the foundation for a valuable tool that can assist developers and the programming community. By implementing the recommendations and next steps, we can refine and expand this tool to further contribute to the developer community."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
